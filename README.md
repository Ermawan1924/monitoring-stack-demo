# ğŸš€ Observability Stack (Prometheus + Grafana + Loki + Tempo + Alertmanager)

A complete observability lab stack built using Docker Compose.

**Includes:**

* ğŸ“Š **Prometheus** (metrics)
* ğŸ“ˆ **Grafana** (dashboards & Explore)
* ğŸ“œ **Loki** (logs)
* ğŸ” **Tempo** (traces)
* ğŸš¨ **Alertmanager** (alert routing)
* ğŸ–¥ **Node Exporter** (host metrics)
* ğŸ“¦ **cAdvisor** (container metrics)
* ğŸ§ª **Demo Go App** (RED + USE testing)

---

## ğŸ§± Architecture

```text
Demo App
  â”œâ”€ Metrics  â†’ Prometheus (/metrics)
  â”œâ”€ Traces   â†’ Tempo (OTLP)
  â””â”€ Logs     â†’ Loki (via promtail/docker logging)

Prometheus
  â”œâ”€ Scrape: node-exporter, cadvisor, demo-app
  â”œâ”€ Rules: alert rules (*.yml)
  â””â”€ Sends alerts â†’ Alertmanager

Grafana
  â”œâ”€ Datasource: Prometheus
  â”œâ”€ Datasource: Loki
  â””â”€ Datasource: Tempo
```

---

## ğŸ“¦ Components

### Prometheus

* Scrapes metrics from exporters and the demo app
* Evaluates alert rules
* Sends alerts to Alertmanager

### Alertmanager

* Receives alerts from Prometheus
* Groups / routes notifications (email / Telegram, etc.)

### Grafana

* Dashboards for infra + app
* Explore for Logs (Loki) and Traces (Tempo)

### Loki

* Centralized logging backend

### Tempo

* Distributed tracing backend (query using TraceQL in Grafana Explore)

### Demo App

* Exposes Prometheus metrics:

  * `http_requests_total{method,route,status}`
  * `http_request_duration_seconds_bucket{method,route}`
* Emits OpenTelemetry traces to Tempo
* Endpoints:

  * `GET /` (200)
  * `GET /slow` (random delay)
  * `GET /error` (500)
  * `GET /metrics`

---

## âœ… Requirements

* Docker
* Docker Compose

---

## ğŸš€ Quick Start

```bash
git clone <your-repo-url>
cd monitoring-stack

docker compose up -d
```

---

## ğŸŒ Access URLs

| Service      | URL                                            |
| ------------ | ---------------------------------------------- |
| Grafana      | [http://localhost:3000](http://localhost:3000) |
| Prometheus   | [http://localhost:9090](http://localhost:9090) |
| Alertmanager | [http://localhost:9093](http://localhost:9093) |
| Demo App     | [http://localhost:8081](http://localhost:8081) |

**Grafana default login** (if not changed):

```text
admin / admin
```

---

## ğŸ§ª Testing Alerts

> Ensure Prometheus has loaded rules:

* `http://localhost:9090/rules`
* `http://localhost:9090/alerts`

### 1) InstanceDown

Stop a target (example: node-exporter):

```bash
docker stop node-exporter
```

Wait ~1 minute (`for: 1m`) â†’ alert should fire.

Restore:

```bash
docker start node-exporter
```

---

### 2) High CPU Host (USE)

Generate CPU load (adjust `--cpu` to your core count):

```bash
docker run --rm -it alpine sh -lc 'apk add --no-cache stress-ng && stress-ng --cpu 4 --timeout 5m'
```

Wait ~3 minutes (`for: 3m`) â†’ alert should fire.

---

### 3) High 5xx Rate (RED)

Generate 5xx responses:

```bash
for i in $(seq 1 200); do
  curl -s http://localhost:8081/error >/dev/null &
done
wait
```

Wait ~1 minute (`for: 1m`) â†’ alert should fire.

---

## ğŸ“Š Useful PromQL

### RED

**Request rate (req/s):**

```promql
sum(rate(http_requests_total[2m]))
```

**5xx error rate (%):**

```promql
100 * sum(rate(http_requests_total{status=~"5.."}[2m]))
  / sum(rate(http_requests_total[2m]))
```

**Latency p95 (seconds):**

```promql
histogram_quantile(
  0.95,
  sum by (le, route) (rate(http_request_duration_seconds_bucket[5m]))
)
```

### USE

**CPU Utilization (%):**

```promql
100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)
```

**Memory Utilization (%):**

```promql
100 * (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes))
```

---

## ğŸ” Tempo TraceQL Examples

Grafana â†’ **Explore** â†’ datasource **Tempo** â†’ use **TraceQL**.

**All traces:**

```traceql
{}
```

**Filter by service:**

```traceql
{ resource.service.name = "demo-app" }
```

**Slow traces:**

```traceql
{ duration > 500ms }
```

**Errors:**

```traceql
{ status = error }
```

---

## ğŸ“ Project Structure

```text
monitoring-stack/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ prometheus/
â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â””â”€â”€ rules/
â”œâ”€â”€ alertmanager/
â”‚   â””â”€â”€ alertmanager.yml
â”œâ”€â”€ grafana/
â”‚   â””â”€â”€ provisioning/
â”œâ”€â”€ loki/
â”œâ”€â”€ tempo/
â””â”€â”€ demo-app/
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ go.mod
    â”œâ”€â”€ go.sum
    â””â”€â”€ main.go
```

---

## ğŸ¯ Learning Goals

This lab demonstrates:

* Metrics scraping & dashboards
* RED vs USE monitoring methods
* Alerting with Prometheus + Alertmanager
* Centralized logs with Loki
* Distributed tracing with Tempo + TraceQL

---

## ğŸ“Œ Next Improvements

* SLO / burn-rate alerting
* Service graph and span metrics (Tempo metrics generator)
* Kubernetes deployment (kube-state-metrics, kubelet scrape)
* CI pipeline (lint, build, scan)
* Persistent storage / backup strategy